test compile precise-output
target x86_64 has_avx=false has_fma=false

function %fma_f32(f32, f32, f32) -> f32 {
block0(v0: f32, v1: f32, v2: f32):
    v3 = fma v0, v1, v2
    return v3
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   load_ext_name r8, %FmaF32+0
;   call *r8
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movabs r8, 0 ; reloc_external Abs8 %FmaF32 0
;   call r8
;   mov rsp, rbp
;   pop rbp
;   ret

function %fma_f64(f64, f64, f64) -> f64 {
block0(v0: f64, v1: f64, v2: f64):
    v3 = fma v0, v1, v2
    return v3
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   load_ext_name r8, %FmaF64+0
;   call *r8
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movabs r8, 0 ; reloc_external Abs8 %FmaF64 0
;   call r8
;   mov rsp, rbp
;   pop rbp
;   ret

function %fma_f32x4(f32x4, f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4, v2: f32x4):
    v3 = fma v0, v1, v2
    return v3
}

; VCode:
;   push rbp
;   mov rbp, rsp
;   sub rsp, rsp, $96
; block0:
;   movdqu xmmword ptr [rsp], xmm0
;   movdqu xmmword ptr [rsp + 0x10], xmm1
;   movdqu xmmword ptr [rsp + 0x20], xmm2
;   load_ext_name r8, %FmaF32+0
;   movdqu xmm0, xmmword ptr [rsp]
;   movdqu xmm1, xmmword ptr [rsp + 0x10]
;   movdqu xmm2, xmmword ptr [rsp + 0x20]
;   call *r8
;   movdqu xmmword ptr [rsp + 0x30], xmm0
;   movdqu xmm4, xmmword ptr [rsp]
;   pshufd xmm0, xmm4, 1
;   movdqu xmm8, xmmword ptr [rsp + 0x10]
;   pshufd xmm1, xmm8, 1
;   movdqu xmm12, xmmword ptr [rsp + 0x20]
;   pshufd xmm2, xmm12, 1
;   load_ext_name r9, %FmaF32+0
;   call *r9
;   movdqu xmmword ptr [rsp + 0x40], xmm0
;   movdqu xmm4, xmmword ptr [rsp]
;   pshufd xmm0, xmm4, 2
;   movdqu xmm14, xmmword ptr [rsp + 0x10]
;   pshufd xmm1, xmm14, 2
;   movdqu xmm3, xmmword ptr [rsp + 0x20]
;   pshufd xmm2, xmm3, 2
;   load_ext_name r10, %FmaF32+0
;   call *r10
;   movdqu xmmword ptr [rsp + 0x50], xmm0
;   movdqu xmm4, xmmword ptr [rsp]
;   pshufd xmm0, xmm4, 3
;   movdqu xmm1, xmmword ptr [rsp + 0x10]
;   pshufd xmm1, xmm1, 3
;   movdqu xmm2, xmmword ptr [rsp + 0x20]
;   pshufd xmm2, xmm2, 3
;   load_ext_name r11, %FmaF32+0
;   call *r11
;   movdqu xmm4, xmmword ptr [rsp + 0x40]
;   movdqa xmm2, xmm0
;   movdqu xmm0, xmmword ptr [rsp + 0x30]
;   insertps xmm0, xmm0, xmm4, 0x10
;   movdqu xmm1, xmmword ptr [rsp + 0x50]
;   insertps xmm0, xmm0, xmm1, 0x20
;   movdqa xmm3, xmm2
;   insertps xmm0, xmm0, xmm3, 0x30
;   add rsp, rsp, $96
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
;   sub rsp, 0x60
; block1: ; offset 0x8
;   movdqu xmmword ptr [rsp], xmm0
;   movdqu xmmword ptr [rsp + 0x10], xmm1
;   movdqu xmmword ptr [rsp + 0x20], xmm2
;   movabs r8, 0 ; reloc_external Abs8 %FmaF32 0
;   movdqu xmm0, xmmword ptr [rsp]
;   movdqu xmm1, xmmword ptr [rsp + 0x10]
;   movdqu xmm2, xmmword ptr [rsp + 0x20]
;   call r8
;   movdqu xmmword ptr [rsp + 0x30], xmm0
;   movdqu xmm4, xmmword ptr [rsp]
;   pshufd xmm0, xmm4, 1
;   movdqu xmm8, xmmword ptr [rsp + 0x10]
;   pshufd xmm1, xmm8, 1
;   movdqu xmm12, xmmword ptr [rsp + 0x20]
;   pshufd xmm2, xmm12, 1
;   movabs r9, 0 ; reloc_external Abs8 %FmaF32 0
;   call r9
;   movdqu xmmword ptr [rsp + 0x40], xmm0
;   movdqu xmm4, xmmword ptr [rsp]
;   pshufd xmm0, xmm4, 2
;   movdqu xmm14, xmmword ptr [rsp + 0x10]
;   pshufd xmm1, xmm14, 2
;   movdqu xmm3, xmmword ptr [rsp + 0x20]
;   pshufd xmm2, xmm3, 2
;   movabs r10, 0 ; reloc_external Abs8 %FmaF32 0
;   call r10
;   movdqu xmmword ptr [rsp + 0x50], xmm0
;   movdqu xmm4, xmmword ptr [rsp]
;   pshufd xmm0, xmm4, 3
;   movdqu xmm1, xmmword ptr [rsp + 0x10]
;   pshufd xmm1, xmm1, 3
;   movdqu xmm2, xmmword ptr [rsp + 0x20]
;   pshufd xmm2, xmm2, 3
;   movabs r11, 0 ; reloc_external Abs8 %FmaF32 0
;   call r11
;   movdqu xmm4, xmmword ptr [rsp + 0x40]
;   movdqa xmm2, xmm0
;   movdqu xmm0, xmmword ptr [rsp + 0x30]
;   insertps xmm0, xmm4, 0x10
;   movdqu xmm1, xmmword ptr [rsp + 0x50]
;   insertps xmm0, xmm1, 0x20
;   movdqa xmm3, xmm2
;   insertps xmm0, xmm3, 0x30
;   add rsp, 0x60
;   mov rsp, rbp
;   pop rbp
;   ret

function %fma_f64x2(f64x2, f64x2, f64x2) -> f64x2 {
block0(v0: f64x2, v1: f64x2, v2: f64x2):
    v3 = fma v0, v1, v2
    return v3
}

; VCode:
;   push rbp
;   mov rbp, rsp
;   sub rsp, rsp, $64
; block0:
;   movdqu xmmword ptr [rsp], xmm0
;   movdqu xmmword ptr [rsp + 0x10], xmm1
;   movdqu xmmword ptr [rsp + 0x20], xmm2
;   load_ext_name r8, %FmaF64+0
;   movdqu xmm0, xmmword ptr [rsp]
;   movdqu xmm1, xmmword ptr [rsp + 0x10]
;   movdqu xmm2, xmmword ptr [rsp + 0x20]
;   call *r8
;   movdqu xmmword ptr [rsp + 0x30], xmm0
;   movdqu xmm0, xmmword ptr [rsp]
;   pshufd xmm0, xmm0, 238
;   movdqu xmm1, xmmword ptr [rsp + 0x10]
;   pshufd xmm1, xmm1, 238
;   movdqu xmm2, xmmword ptr [rsp + 0x20]
;   pshufd xmm2, xmm2, 238
;   load_ext_name r9, %FmaF64+0
;   call *r9
;   movdqa xmm14, xmm0
;   movdqu xmm0, xmmword ptr [rsp + 0x30]
;   movlhps xmm0, xmm0, xmm14
;   add rsp, rsp, $64
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
;   sub rsp, 0x40
; block1: ; offset 0x8
;   movdqu xmmword ptr [rsp], xmm0
;   movdqu xmmword ptr [rsp + 0x10], xmm1
;   movdqu xmmword ptr [rsp + 0x20], xmm2
;   movabs r8, 0 ; reloc_external Abs8 %FmaF64 0
;   movdqu xmm0, xmmword ptr [rsp]
;   movdqu xmm1, xmmword ptr [rsp + 0x10]
;   movdqu xmm2, xmmword ptr [rsp + 0x20]
;   call r8
;   movdqu xmmword ptr [rsp + 0x30], xmm0
;   movdqu xmm0, xmmword ptr [rsp]
;   pshufd xmm0, xmm0, 0xee
;   movdqu xmm1, xmmword ptr [rsp + 0x10]
;   pshufd xmm1, xmm1, 0xee
;   movdqu xmm2, xmmword ptr [rsp + 0x20]
;   pshufd xmm2, xmm2, 0xee
;   movabs r9, 0 ; reloc_external Abs8 %FmaF64 0
;   call r9
;   movdqa xmm14, xmm0
;   movdqu xmm0, xmmword ptr [rsp + 0x30]
;   movlhps xmm0, xmm14
;   add rsp, 0x40
;   mov rsp, rbp
;   pop rbp
;   ret

