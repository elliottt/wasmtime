test compile precise-output
set enable_llvm_abi_extensions=true
target x86_64

function %f0(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = iadd v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rax, rdi
;   add rax, rax, rdx
;   mov rdx, rsi
;   adc rdx, rdx, rcx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rax, rdi
;   add rax, rdx
;   mov rdx, rsi
;   adc rdx, rcx
;   mov rsp, rbp
;   pop rbp
;   ret

function %f1(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = isub v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rax, rdi
;   sub rax, rax, rdx
;   mov rdx, rsi
;   sbb rdx, rdx, rcx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rax, rdi
;   sub rax, rdx
;   mov rdx, rsi
;   sbb rdx, rcx
;   mov rsp, rbp
;   pop rbp
;   ret

function %f2(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = band v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rax, rdi
;   and rax, rax, rdx
;   mov rdx, rsi
;   and rdx, rdx, rcx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rax, rdi
;   and rax, rdx
;   mov rdx, rsi
;   and rdx, rcx
;   mov rsp, rbp
;   pop rbp
;   ret

function %f3(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = bor v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rax, rdi
;   or rax, rax, rdx
;   mov rdx, rsi
;   or rdx, rdx, rcx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rax, rdi
;   or rax, rdx
;   mov rdx, rsi
;   or rdx, rcx
;   mov rsp, rbp
;   pop rbp
;   ret

function %f4(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = bxor v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rax, rdi
;   xor rax, rax, rdx
;   mov rdx, rsi
;   xor rdx, rdx, rcx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rax, rdi
;   xor rax, rdx
;   mov rdx, rsi
;   xor rdx, rcx
;   mov rsp, rbp
;   pop rbp
;   ret

function %f5(i128) -> i128 {
block0(v0: i128):
    v1 = bnot v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rax, rdi
;   not rax, rax
;   mov rdx, rsi
;   not rdx, rdx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rax, rdi
;   not rax
;   mov rdx, rsi
;   not rdx
;   mov rsp, rbp
;   pop rbp
;   ret

function %f6(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = imul v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rax, rdx
;   mov rdx, rdi
;   imul rdx, rdx, rcx
;   mov rcx, rax
;   mov rax, rdi
;   mov r10, rsi
;   imul r10, r10, rcx
;   add rdx, rdx, r10
;   mov r9, rdx
;   mul rax, rdx, rax, rcx
;   mov rcx, rdx
;   mov rdx, r9
;   add rdx, rdx, rcx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rax, rdx
;   mov rdx, rdi
;   imul rdx, rcx
;   mov rcx, rax
;   mov rax, rdi
;   mov r10, rsi
;   imul r10, rcx
;   add rdx, r10
;   mov r9, rdx
;   mul rcx
;   mov rcx, rdx
;   mov rdx, r9
;   add rdx, rcx
;   mov rsp, rbp
;   pop rbp
;   ret

function %f7(i64, i64) -> i128 {
block0(v0: i64, v1: i64):
    v2 = iconcat.i64 v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rdx, rsi
;   mov rax, rdi
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rdx, rsi
;   mov rax, rdi
;   mov rsp, rbp
;   pop rbp
;   ret

function %f8(i128) -> i64, i64 {
block0(v0: i128):
    v1, v2 = isplit.i128 v0
    return v1, v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rdx, rsi
;   mov rax, rdi
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rdx, rsi
;   mov rax, rdi
;   mov rsp, rbp
;   pop rbp
;   ret

function %f9(i128, i128) -> i8 {
block0(v0: i128, v1: i128):
    v2 = icmp eq v0, v1
    v3 = icmp ne v0, v1
    v4 = icmp slt v0, v1
    v5 = icmp sle v0, v1
    v6 = icmp sgt v0, v1
    v7 = icmp sge v0, v1
    v8 = icmp ult v0, v1
    v9 = icmp ule v0, v1
    v10 = icmp ugt v0, v1
    v11 = icmp uge v0, v1
    v12 = band v2, v3
    v13 = band v4, v5
    v14 = band v6, v7
    v15 = band v8, v9
    v16 = band v10, v11
    v17 = band v12, v13
    v18 = band v14, v15
    v19 = band v17, v18
    v20 = band v19, v16
    return v20
}

; VCode:
;   push rbp
;   mov rbp, rsp
;   sub rsp, rsp, $64
;   mov qword ptr [rsp + 0x10], rbx
;   mov qword ptr [rsp + 0x18], r12
;   mov qword ptr [rsp + 0x20], r13
;   mov qword ptr [rsp + 0x28], r14
;   mov qword ptr [rsp + 0x30], r15
; block0:
;   cmp rdi, rdx
;   setz r9b
;   cmp rsi, rcx
;   setz r10b
;   and r9, r9, r10
;   test r9, $1
;   setnz al
;   cmp rdi, rdx
;   setnz r8b
;   cmp rsi, rcx
;   setnz r9b
;   or r8, r8, r9
;   test r8, $1
;   setnz r9b
;   mov qword ptr [rsp], r9
;   cmp rsi, rcx
;   setl r8b
;   setz r10b
;   cmp rdi, rdx
;   setb r11b
;   and r10, r10, r11
;   or r8, r8, r10
;   test r8, $1
;   setnz r10b
;   cmp rsi, rcx
;   setl r11b
;   setz r8b
;   cmp rdi, rdx
;   setbe r15b
;   and r8, r8, r15
;   or r11, r11, r8
;   test r11, $1
;   setnz r8b
;   cmp rsi, rcx
;   setnle r11b
;   setz r12b
;   cmp rdi, rdx
;   setnbe r13b
;   and r12, r12, r13
;   or r11, r11, r12
;   test r11, $1
;   setnz r11b
;   cmp rsi, rcx
;   setnle r15b
;   setz bl
;   cmp rdi, rdx
;   setnb r12b
;   and rbx, rbx, r12
;   or r15, r15, rbx
;   test r15, $1
;   setnz r13b
;   cmp rsi, rcx
;   setb r14b
;   setz r15b
;   cmp rdi, rdx
;   setb bl
;   and r15, r15, rbx
;   or r14, r14, r15
;   test r14, $1
;   setnz r14b
;   cmp rsi, rcx
;   setb bl
;   setz r12b
;   cmp rdi, rdx
;   setbe r15b
;   and r12, r12, r15
;   or rbx, rbx, r12
;   test rbx, $1
;   setnz r15b
;   cmp rsi, rcx
;   setnbe bl
;   setz r12b
;   cmp rdi, rdx
;   setnbe r9b
;   and r12, r12, r9
;   or rbx, rbx, r12
;   test rbx, $1
;   setnz bl
;   cmp rsi, rcx
;   setnbe sil
;   setz cl
;   cmp rdi, rdx
;   setnb dil
;   and rcx, rcx, rdi
;   or rsi, rsi, rcx
;   test rsi, $1
;   setnz sil
;   mov rcx, qword ptr [rsp]
;   and eax, eax, ecx
;   and r10d, r10d, r8d
;   and r11d, r11d, r13d
;   and r14d, r14d, r15d
;   and ebx, ebx, esi
;   and eax, eax, r10d
;   and r11d, r11d, r14d
;   and eax, eax, r11d
;   and eax, eax, ebx
;   mov rbx, qword ptr [rsp + 0x10]
;   mov r12, qword ptr [rsp + 0x18]
;   mov r13, qword ptr [rsp + 0x20]
;   mov r14, qword ptr [rsp + 0x28]
;   mov r15, qword ptr [rsp + 0x30]
;   add rsp, rsp, $64
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
;   sub rsp, 0x40
;   mov qword ptr [rsp + 0x10], rbx
;   mov qword ptr [rsp + 0x18], r12
;   mov qword ptr [rsp + 0x20], r13
;   mov qword ptr [rsp + 0x28], r14
;   mov qword ptr [rsp + 0x30], r15
; block1: ; offset 0x21
;   cmp rdi, rdx
;   sete r9b
;   cmp rsi, rcx
;   sete r10b
;   and r9, r10
;   test r9, 1
;   setne al
;   cmp rdi, rdx
;   setne r8b
;   cmp rsi, rcx
;   setne r9b
;   or r8, r9
;   test r8, 1
;   setne r9b
;   mov qword ptr [rsp], r9
;   cmp rsi, rcx
;   setl r8b
;   sete r10b
;   cmp rdi, rdx
;   setb r11b
;   and r10, r11
;   or r8, r10
;   test r8, 1
;   setne r10b
;   cmp rsi, rcx
;   setl r11b
;   sete r8b
;   cmp rdi, rdx
;   setbe r15b
;   and r8, r15
;   or r11, r8
;   test r11, 1
;   setne r8b
;   cmp rsi, rcx
;   setg r11b
;   sete r12b
;   cmp rdi, rdx
;   seta r13b
;   and r12, r13
;   or r11, r12
;   test r11, 1
;   setne r11b
;   cmp rsi, rcx
;   setg r15b
;   sete bl
;   cmp rdi, rdx
;   setae r12b
;   and rbx, r12
;   or r15, rbx
;   test r15, 1
;   setne r13b
;   cmp rsi, rcx
;   setb r14b
;   sete r15b
;   cmp rdi, rdx
;   setb bl
;   and r15, rbx
;   or r14, r15
;   test r14, 1
;   setne r14b
;   cmp rsi, rcx
;   setb bl
;   sete r12b
;   cmp rdi, rdx
;   setbe r15b
;   and r12, r15
;   or rbx, r12
;   test rbx, 1
;   setne r15b
;   cmp rsi, rcx
;   seta bl
;   sete r12b
;   cmp rdi, rdx
;   seta r9b
;   and r12, r9
;   or rbx, r12
;   test rbx, 1
;   setne bl
;   cmp rsi, rcx
;   seta sil
;   sete cl
;   cmp rdi, rdx
;   setae dil
;   and rcx, rdi
;   or rsi, rcx
;   test rsi, 1
;   setne sil
;   mov rcx, qword ptr [rsp]
;   and eax, ecx
;   and r10d, r8d
;   and r11d, r13d
;   and r14d, r15d
;   and ebx, esi
;   and eax, r10d
;   and r11d, r14d
;   and eax, r11d
;   and eax, ebx
;   mov rbx, qword ptr [rsp + 0x10]
;   mov r12, qword ptr [rsp + 0x18]
;   mov r13, qword ptr [rsp + 0x20]
;   mov r14, qword ptr [rsp + 0x28]
;   mov r15, qword ptr [rsp + 0x30]
;   add rsp, 0x40
;   mov rsp, rbp
;   pop rbp
;   ret

function %f10(i128) -> i32 {
block0(v0: i128):
    brif v0, block2, block1

block1:
    v1 = iconst.i32 1
    return v1

block2:
    v2 = iconst.i32 2
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   cmp rdi, $0
;   setz r9b
;   cmp rsi, $0
;   setz sil
;   test sil, r9b
;   jz label2; j label1
; block1:
;   mov eax, 0x1
;   mov rsp, rbp
;   pop rbp
;   ret
; block2:
;   mov eax, 0x2
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   cmp rdi, 0
;   sete r9b
;   cmp rsi, 0
;   sete sil
;   test sil, r9b
;   je 0x27
; block2: ; offset 0x1d
;   mov eax, 1
;   mov rsp, rbp
;   pop rbp
;   ret
; block3: ; offset 0x27
;   mov eax, 2
;   mov rsp, rbp
;   pop rbp
;   ret

function %f11(i128) -> i32 {
block0(v0: i128):
    brif v0, block1, block2

block1:
    v1 = iconst.i32 1
    return v1

block2:
    v2 = iconst.i32 2
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   cmp rdi, $0
;   setz r9b
;   cmp rsi, $0
;   setz sil
;   test sil, r9b
;   jz label2; j label1
; block1:
;   mov eax, 0x2
;   mov rsp, rbp
;   pop rbp
;   ret
; block2:
;   mov eax, 0x1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   cmp rdi, 0
;   sete r9b
;   cmp rsi, 0
;   sete sil
;   test sil, r9b
;   je 0x27
; block2: ; offset 0x1d
;   mov eax, 2
;   mov rsp, rbp
;   pop rbp
;   ret
; block3: ; offset 0x27
;   mov eax, 1
;   mov rsp, rbp
;   pop rbp
;   ret

function %f12(i64) -> i128 {
block0(v0: i64):
    v1 = uextend.i128 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rax, rdi
;   xor rdx, rdx, rdx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rax, rdi
;   xor rdx, rdx
;   mov rsp, rbp
;   pop rbp
;   ret

function %f13(i64) -> i128 {
block0(v0: i64):
    v1 = sextend.i128 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rdx, rdi
;   sar rdx, rdx, 0x3f
;   mov rax, rdi
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rdx, rdi
;   sar rdx, 0x3f
;   mov rax, rdi
;   mov rsp, rbp
;   pop rbp
;   ret

function %f14(i8) -> i128 {
block0(v0: i8):
    v1 = sextend.i128 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movsx rax, dil
;   mov rdx, rax
;   sar rdx, rdx, 0x3f
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movsx rax, dil
;   mov rdx, rax
;   sar rdx, 0x3f
;   mov rsp, rbp
;   pop rbp
;   ret

function %f15(i8) -> i128 {
block0(v0: i8):
    v1 = uextend.i128 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movzx rax, dil
;   xor rdx, rdx, rdx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movzx rax, dil
;   xor rdx, rdx
;   mov rsp, rbp
;   pop rbp
;   ret

function %f16(i128) -> i64 {
block0(v0: i128):
    v1 = ireduce.i64 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rax, rdi
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rax, rdi
;   mov rsp, rbp
;   pop rbp
;   ret

function %f17(i128) -> i8 {
block0(v0: i128):
    v1 = ireduce.i8 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rax, rdi
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rax, rdi
;   mov rsp, rbp
;   pop rbp
;   ret

function %f18(i8) -> i128 {
block0(v0: i8):
    v1 = uextend.i128 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movzx rax, dil
;   xor rdx, rdx, rdx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movzx rax, dil
;   xor rdx, rdx
;   mov rsp, rbp
;   pop rbp
;   ret

function %f19(i128) -> i128 {
block0(v0: i128):
    v1 = popcnt.i128 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rax, rdi
;   shr rax, rax, 0x1
;   movabs r8, 0x7777777777777777
;   and rax, rax, r8
;   mov r9, rdi
;   sub r9, r9, rax
;   shr rax, rax, 0x1
;   and rax, rax, r8
;   sub r9, r9, rax
;   shr rax, rax, 0x1
;   and rax, rax, r8
;   sub r9, r9, rax
;   mov rax, r9
;   shr rax, rax, 0x4
;   add rax, rax, r9
;   movabs rdi, 0xf0f0f0f0f0f0f0f
;   and rax, rax, rdi
;   movabs rdx, 0x101010101010101
;   imul rax, rax, rdx
;   shr rax, rax, 0x38
;   mov rdi, rsi
;   shr rdi, rdi, 0x1
;   movabs rcx, 0x7777777777777777
;   and rdi, rdi, rcx
;   mov rdx, rsi
;   sub rdx, rdx, rdi
;   shr rdi, rdi, 0x1
;   and rdi, rdi, rcx
;   sub rdx, rdx, rdi
;   shr rdi, rdi, 0x1
;   and rdi, rdi, rcx
;   sub rdx, rdx, rdi
;   mov rsi, rdx
;   shr rsi, rsi, 0x4
;   add rsi, rsi, rdx
;   movabs r10, 0xf0f0f0f0f0f0f0f
;   and rsi, rsi, r10
;   movabs rcx, 0x101010101010101
;   imul rsi, rsi, rcx
;   shr rsi, rsi, 0x38
;   add rax, rax, rsi
;   xor rdx, rdx, rdx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rax, rdi
;   shr rax, 1
;   movabs r8, 0x7777777777777777
;   and rax, r8
;   mov r9, rdi
;   sub r9, rax
;   shr rax, 1
;   and rax, r8
;   sub r9, rax
;   shr rax, 1
;   and rax, r8
;   sub r9, rax
;   mov rax, r9
;   shr rax, 4
;   add rax, r9
;   movabs rdi, 0xf0f0f0f0f0f0f0f
;   and rax, rdi
;   movabs rdx, 0x101010101010101
;   imul rax, rdx
;   shr rax, 0x38
;   mov rdi, rsi
;   shr rdi, 1
;   movabs rcx, 0x7777777777777777
;   and rdi, rcx
;   mov rdx, rsi
;   sub rdx, rdi
;   shr rdi, 1
;   and rdi, rcx
;   sub rdx, rdi
;   shr rdi, 1
;   and rdi, rcx
;   sub rdx, rdi
;   mov rsi, rdx
;   shr rsi, 4
;   add rsi, rdx
;   movabs r10, 0xf0f0f0f0f0f0f0f
;   and rsi, r10
;   movabs rcx, 0x101010101010101
;   imul rsi, rcx
;   shr rsi, 0x38
;   add rax, rsi
;   xor rdx, rdx
;   mov rsp, rbp
;   pop rbp
;   ret

function %f20(i128) -> i128 {
block0(v0: i128):
    v1 = bitrev.i128 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movabs rcx, 0x5555555555555555
;   mov rdx, rsi
;   and rdx, rdx, rcx
;   mov r11, rsi
;   shr r11, r11, 0x1
;   and r11, r11, rcx
;   shl rdx, rdx, 0x1
;   or rdx, rdx, r11
;   movabs r9, 0x3333333333333333
;   mov r10, rdx
;   and r10, r10, r9
;   shr rdx, rdx, 0x2
;   and rdx, rdx, r9
;   shl r10, r10, 0x2
;   or r10, r10, rdx
;   movabs rsi, 0xf0f0f0f0f0f0f0f
;   mov rax, r10
;   and rax, rax, rsi
;   shr r10, r10, 0x4
;   and r10, r10, rsi
;   shl rax, rax, 0x4
;   or rax, rax, r10
;   movabs rcx, 0xff00ff00ff00ff
;   mov rdx, rax
;   and rdx, rdx, rcx
;   shr rax, rax, 0x8
;   and rax, rax, rcx
;   shl rdx, rdx, 0x8
;   or rdx, rdx, rax
;   movabs r10, 0xffff0000ffff
;   mov r9, rdx
;   and r9, r9, r10
;   shr rdx, rdx, 0x10
;   and rdx, rdx, r10
;   shl r9, r9, 0x10
;   or r9, r9, rdx
;   movabs rsi, 0xffffffff
;   mov rax, r9
;   and rax, rax, rsi
;   shr r9, r9, 0x20
;   shl rax, rax, 0x20
;   or rax, rax, r9
;   movabs rdx, 0x5555555555555555
;   mov rcx, rdi
;   and rcx, rcx, rdx
;   mov r9, rdi
;   shr r9, r9, 0x1
;   and r9, r9, rdx
;   shl rcx, rcx, 0x1
;   or rcx, rcx, r9
;   movabs rdx, 0x3333333333333333
;   mov r8, rcx
;   and r8, r8, rdx
;   shr rcx, rcx, 0x2
;   and rcx, rcx, rdx
;   shl r8, r8, 0x2
;   or r8, r8, rcx
;   movabs r10, 0xf0f0f0f0f0f0f0f
;   mov r11, r8
;   and r11, r11, r10
;   shr r8, r8, 0x4
;   and r8, r8, r10
;   shl r11, r11, 0x4
;   or r11, r11, r8
;   movabs rdi, 0xff00ff00ff00ff
;   mov rcx, r11
;   and rcx, rcx, rdi
;   shr r11, r11, 0x8
;   and r11, r11, rdi
;   shl rcx, rcx, 0x8
;   or rcx, rcx, r11
;   movabs rdx, 0xffff0000ffff
;   mov r8, rcx
;   and r8, r8, rdx
;   shr rcx, rcx, 0x10
;   and rcx, rcx, rdx
;   shl r8, r8, 0x10
;   or r8, r8, rcx
;   movabs r10, 0xffffffff
;   mov rdx, r8
;   and rdx, rdx, r10
;   shr r8, r8, 0x20
;   shl rdx, rdx, 0x20
;   or rdx, rdx, r8
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movabs rcx, 0x5555555555555555
;   mov rdx, rsi
;   and rdx, rcx
;   mov r11, rsi
;   shr r11, 1
;   and r11, rcx
;   shl rdx, 1
;   or rdx, r11
;   movabs r9, 0x3333333333333333
;   mov r10, rdx
;   and r10, r9
;   shr rdx, 2
;   and rdx, r9
;   shl r10, 2
;   or r10, rdx
;   movabs rsi, 0xf0f0f0f0f0f0f0f
;   mov rax, r10
;   and rax, rsi
;   shr r10, 4
;   and r10, rsi
;   shl rax, 4
;   or rax, r10
;   movabs rcx, 0xff00ff00ff00ff
;   mov rdx, rax
;   and rdx, rcx
;   shr rax, 8
;   and rax, rcx
;   shl rdx, 8
;   or rdx, rax
;   movabs r10, 0xffff0000ffff
;   mov r9, rdx
;   and r9, r10
;   shr rdx, 0x10
;   and rdx, r10
;   shl r9, 0x10
;   or r9, rdx
;   movabs rsi, 0xffffffff
;   mov rax, r9
;   and rax, rsi
;   shr r9, 0x20
;   shl rax, 0x20
;   or rax, r9
;   movabs rdx, 0x5555555555555555
;   mov rcx, rdi
;   and rcx, rdx
;   mov r9, rdi
;   shr r9, 1
;   and r9, rdx
;   shl rcx, 1
;   or rcx, r9
;   movabs rdx, 0x3333333333333333
;   mov r8, rcx
;   and r8, rdx
;   shr rcx, 2
;   and rcx, rdx
;   shl r8, 2
;   or r8, rcx
;   movabs r10, 0xf0f0f0f0f0f0f0f
;   mov r11, r8
;   and r11, r10
;   shr r8, 4
;   and r8, r10
;   shl r11, 4
;   or r11, r8
;   movabs rdi, 0xff00ff00ff00ff
;   mov rcx, r11
;   and rcx, rdi
;   shr r11, 8
;   and r11, rdi
;   shl rcx, 8
;   or rcx, r11
;   movabs rdx, 0xffff0000ffff
;   mov r8, rcx
;   and r8, rdx
;   shr rcx, 0x10
;   and rcx, rdx
;   shl r8, 0x10
;   or r8, rcx
;   movabs r10, 0xffffffff
;   mov rdx, r8
;   and rdx, r10
;   shr r8, 0x20
;   shl rdx, 0x20
;   or rdx, r8
;   mov rsp, rbp
;   pop rbp
;   ret

function %f21(i128, i64) {
block0(v0: i128, v1: i64):
    store.i128 v0, v1
    return
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov qword ptr [rdx + 0x0], rdi
;   mov qword ptr [rdx + 0x8], rsi
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov qword ptr [rdx], rdi ; trap: heap_oob
;   mov qword ptr [rdx + 8], rsi ; trap: heap_oob
;   mov rsp, rbp
;   pop rbp
;   ret

function %f22(i64) -> i128 {
block0(v0: i64):
    v1 = load.i128 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rax, qword ptr [rdi + 0x0]
;   mov rdx, qword ptr [rdi + 0x8]
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rax, qword ptr [rdi] ; trap: heap_oob
;   mov rdx, qword ptr [rdi + 8] ; trap: heap_oob
;   mov rsp, rbp
;   pop rbp
;   ret

function %f23(i128, i8) -> i128 {
block0(v0: i128, v1: i8):
    v2 = iconst.i64 0
    v3 = uextend.i128 v2
    brif v1, block1(v3), block2(v3)

block1(v4: i128):
    v5 = iconst.i64 1
    v6 = uextend.i128 v5
    v7 = iadd.i128 v4, v6
    return v7

block2(v8: i128):
    v9 = iconst.i64 2
    v10 = uextend.i128 v9
    v11 = iadd.i128 v8, v10
    return v11
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   xor rax, rax, rax
;   xor r9, r9, r9
;   mov r8, r9
;   test dl, dl
;   jnz label2; j label1
; block1:
;   mov r9d, 0x2
;   xor r10, r10, r10
;   add rax, rax, r9
;   mov rdx, r8
;   adc rdx, rdx, r10
;   mov rsp, rbp
;   pop rbp
;   ret
; block2:
;   mov rdx, r8
;   mov r10d, 0x1
;   xor r11, r11, r11
;   add rax, rax, r10
;   adc rdx, rdx, r11
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   xor rax, rax
;   xor r9, r9
;   mov r8, r9
;   test dl, dl
;   jne 0x2c
; block2: ; offset 0x15
;   mov r9d, 2
;   xor r10, r10
;   add rax, r9
;   mov rdx, r8
;   adc rdx, r10
;   mov rsp, rbp
;   pop rbp
;   ret
; block3: ; offset 0x2c
;   mov rdx, r8
;   mov r10d, 1
;   xor r11, r11
;   add rax, r10
;   adc rdx, r11
;   mov rsp, rbp
;   pop rbp
;   ret

function %f24(i128, i128, i64, i128, i128, i128) -> i128 {

block0(v0: i128, v1: i128, v2: i64, v3: i128, v4: i128, v5: i128):
    v6 = iadd.i128 v0, v1
    v7 = uextend.i128 v2
    v8 = iadd.i128 v3, v7
    v9 = iadd.i128 v4, v5
    v10 = iadd.i128 v6, v8
    v11 = iadd.i128 v9, v10
    return v11
}

; VCode:
;   push rbp
;   mov rbp, rsp
;   sub rsp, rsp, $32
;   mov qword ptr [rsp + 0x0], rbx
;   mov qword ptr [rsp + 0x8], r12
;   mov qword ptr [rsp + 0x10], r14
;   mov qword ptr [rsp + 0x18], r15
; block0:
;   mov r14, r8
;   mov rbx, rcx
;   mov rcx, rdx
;   mov r15, qword ptr [rbp + 0x10]
;   mov rax, qword ptr [rbp + 0x18]
;   mov rdx, qword ptr [rbp + 0x20]
;   mov r11, qword ptr [rbp + 0x28]
;   mov r10, qword ptr [rbp + 0x30]
;   mov r8, rdi
;   add r8, r8, rcx
;   mov rdi, rbx
;   mov rcx, rsi
;   adc rcx, rcx, rdi
;   xor rdi, rdi, rdi
;   mov r12, r14
;   mov rsi, r9
;   add rsi, rsi, r12
;   adc r15, r15, rdi
;   add rax, rax, r11
;   adc rdx, rdx, r10
;   add r8, r8, rsi
;   adc rcx, rcx, r15
;   add rax, rax, r8
;   adc rdx, rdx, rcx
;   mov rbx, qword ptr [rsp + 0x0]
;   mov r12, qword ptr [rsp + 0x8]
;   mov r14, qword ptr [rsp + 0x10]
;   mov r15, qword ptr [rsp + 0x18]
;   add rsp, rsp, $32
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
;   sub rsp, 0x20
;   mov qword ptr [rsp], rbx
;   mov qword ptr [rsp + 8], r12
;   mov qword ptr [rsp + 0x10], r14
;   mov qword ptr [rsp + 0x18], r15
; block1: ; offset 0x1b
;   mov r14, r8
;   mov rbx, rcx
;   mov rcx, rdx
;   mov r15, qword ptr [rbp + 0x10]
;   mov rax, qword ptr [rbp + 0x18]
;   mov rdx, qword ptr [rbp + 0x20]
;   mov r11, qword ptr [rbp + 0x28]
;   mov r10, qword ptr [rbp + 0x30]
;   mov r8, rdi
;   add r8, rcx
;   mov rdi, rbx
;   mov rcx, rsi
;   adc rcx, rdi
;   xor rdi, rdi
;   mov r12, r14
;   mov rsi, r9
;   add rsi, r12
;   adc r15, rdi
;   add rax, r11
;   adc rdx, r10
;   add r8, rsi
;   adc rcx, r15
;   add rax, r8
;   adc rdx, rcx
;   mov rbx, qword ptr [rsp]
;   mov r12, qword ptr [rsp + 8]
;   mov r14, qword ptr [rsp + 0x10]
;   mov r15, qword ptr [rsp + 0x18]
;   add rsp, 0x20
;   mov rsp, rbp
;   pop rbp
;   ret

function %f25(i128) -> i128, i128, i128, i64, i128, i128 {
block0(v0: i128):
    v1 = ireduce.i64 v0
    return v0, v0, v0, v1, v0, v0
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov qword ptr [rdx + 0x0], rdi
;   mov qword ptr [rdx + 0x8], rsi
;   mov qword ptr [rdx + 0x10], rdi
;   mov qword ptr [rdx + 0x18], rsi
;   mov qword ptr [rdx + 0x20], rdi
;   mov qword ptr [rdx + 0x28], rdi
;   mov qword ptr [rdx + 0x30], rsi
;   mov qword ptr [rdx + 0x38], rdi
;   mov rax, rdi
;   mov qword ptr [rdx + 0x40], rsi
;   mov rdx, rsi
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov qword ptr [rdx], rdi
;   mov qword ptr [rdx + 8], rsi
;   mov qword ptr [rdx + 0x10], rdi
;   mov qword ptr [rdx + 0x18], rsi
;   mov qword ptr [rdx + 0x20], rdi
;   mov qword ptr [rdx + 0x28], rdi
;   mov qword ptr [rdx + 0x30], rsi
;   mov qword ptr [rdx + 0x38], rdi
;   mov rax, rdi
;   mov qword ptr [rdx + 0x40], rsi
;   mov rdx, rsi
;   mov rsp, rbp
;   pop rbp
;   ret

function %f26(i128, i128) -> i128, i128 {
    fn0 = %g(i128, i128) -> i128, i128
block0(v0: i128, v1: i128):
    v2, v3 = call fn0(v0, v1)
    return v2, v3
}

; VCode:
;   push rbp
;   mov rbp, rsp
;   sub rsp, rsp, $16
;   mov qword ptr [rsp + 0x0], r13
; block0:
;   mov r13, r8
;   sub rsp, rsp, $16
;   virtual_sp_offset_adjust 16
;   lea r8, qword ptr [rsp + 0x0]
;   load_ext_name r9, %g+0
;   call *r9
;   mov r8, qword ptr [rsp + 0x0]
;   mov r9, qword ptr [rsp + 0x8]
;   add rsp, rsp, $16
;   virtual_sp_offset_adjust -16
;   mov rcx, r13
;   mov qword ptr [rcx + 0x0], r8
;   mov qword ptr [rcx + 0x8], r9
;   mov r13, qword ptr [rsp + 0x0]
;   add rsp, rsp, $16
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
;   sub rsp, 0x10
;   mov qword ptr [rsp], r13
; block1: ; offset 0xc
;   mov r13, r8
;   sub rsp, 0x10
;   lea r8, [rsp]
;   movabs r9, 0 ; reloc_external Abs8 %g 0
;   call r9
;   mov r8, qword ptr [rsp]
;   mov r9, qword ptr [rsp + 8]
;   add rsp, 0x10
;   mov rcx, r13
;   mov qword ptr [rcx], r8
;   mov qword ptr [rcx + 8], r9
;   mov r13, qword ptr [rsp]
;   add rsp, 0x10
;   mov rsp, rbp
;   pop rbp
;   ret

function %f27(i128) -> i128 {
block0(v0: i128):
    v1 = clz.i128 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov r8, rdi
;   movabs rcx, 0xffffffffffffffff
;   bsr r9, rsi
;   cmovz r9, rcx, r9
;   mov edi, 0x3f
;   sub rdi, rdi, r9
;   movabs rdx, 0xffffffffffffffff
;   bsr r10, r8
;   cmovz r10, rdx, r10
;   mov eax, 0x3f
;   sub rax, rax, r10
;   add rax, rax, $64
;   cmp rdi, $64
;   cmovnz rax, rdi, rax
;   xor rdx, rdx, rdx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov r8, rdi
;   mov rcx, 0xffffffffffffffff
;   bsr r9, rsi
;   cmove r9, rcx
;   mov edi, 0x3f
;   sub rdi, r9
;   mov rdx, 0xffffffffffffffff
;   bsr r10, r8
;   cmove r10, rdx
;   mov eax, 0x3f
;   sub rax, r10
;   add rax, 0x40
;   cmp rdi, 0x40
;   cmovne rax, rdi
;   xor rdx, rdx
;   mov rsp, rbp
;   pop rbp
;   ret

function %f28(i128) -> i128 {
block0(v0: i128):
    v1 = ctz.i128 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov ecx, 0x40
;   bsf rax, rdi
;   cmovz rax, rcx, rax
;   mov edi, 0x40
;   bsf rdx, rsi
;   cmovz rdx, rdi, rdx
;   add rdx, rdx, $64
;   cmp rax, $64
;   cmovz rax, rdx, rax
;   xor rdx, rdx, rdx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov ecx, 0x40
;   bsf rax, rdi
;   cmove rax, rcx
;   mov edi, 0x40
;   bsf rdx, rsi
;   cmove rdx, rdi
;   add rdx, 0x40
;   cmp rax, 0x40
;   cmove rax, rdx
;   xor rdx, rdx
;   mov rsp, rbp
;   pop rbp
;   ret

function %f29(i8, i128) -> i8 {
block0(v0: i8, v1: i128):
    v2 = ishl v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rcx, rsi
;   and rcx, rcx, $7
;   mov rax, rdi
;   shl al, al, cl
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rcx, rsi
;   and rcx, 7
;   mov rax, rdi
;   shl al, cl
;   mov rsp, rbp
;   pop rbp
;   ret

function %f30(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = ishl v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rcx, rdx
;   mov r10, rdx
;   mov rdx, rdi
;   shl rdx, rdx, cl
;   mov r11, rsi
;   shl r11, r11, cl
;   mov r10, rcx
;   mov ecx, 0x40
;   mov r8, r10
;   sub rcx, rcx, r8
;   mov r10, rdi
;   shr r10, r10, cl
;   xor rax, rax, rax
;   test r8, $127
;   cmovz r10, rax, r10
;   or r10, r10, r11
;   test r8, $64
;   cmovz rax, rdx, rax
;   cmovz rdx, r10, rdx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rcx, rdx
;   mov r10, rdx
;   mov rdx, rdi
;   shl rdx, cl
;   mov r11, rsi
;   shl r11, cl
;   mov r10, rcx
;   mov ecx, 0x40
;   mov r8, r10
;   sub rcx, r8
;   mov r10, rdi
;   shr r10, cl
;   xor rax, rax
;   test r8, 0x7f
;   cmove r10, rax
;   or r10, r11
;   test r8, 0x40
;   cmove rax, rdx
;   cmove rdx, r10
;   mov rsp, rbp
;   pop rbp
;   ret

function %f31(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = ushr v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rcx, rdx
;   mov r11, rdx
;   mov r8, rdi
;   shr r8, r8, cl
;   mov r10, rsi
;   shr r10, r10, cl
;   mov r11, rcx
;   mov ecx, 0x40
;   mov rdi, r11
;   sub rcx, rcx, rdi
;   mov r11, rsi
;   shl r11, r11, cl
;   xor rdx, rdx, rdx
;   test rdi, $127
;   cmovz r11, rdx, r11
;   or r11, r11, r8
;   test rdi, $64
;   mov rax, r10
;   cmovz rax, r11, rax
;   cmovz rdx, r10, rdx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rcx, rdx
;   mov r11, rdx
;   mov r8, rdi
;   shr r8, cl
;   mov r10, rsi
;   shr r10, cl
;   mov r11, rcx
;   mov ecx, 0x40
;   mov rdi, r11
;   sub rcx, rdi
;   mov r11, rsi
;   shl r11, cl
;   xor rdx, rdx
;   test rdi, 0x7f
;   cmove r11, rdx
;   or r11, r8
;   test rdi, 0x40
;   mov rax, r10
;   cmove rax, r11
;   cmove rdx, r10
;   mov rsp, rbp
;   pop rbp
;   ret

function %f32(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = sshr v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rcx, rdx
;   mov r11, rdx
;   mov r8, rdi
;   shr r8, r8, cl
;   mov r10, rsi
;   sar r10, r10, cl
;   mov r11, rcx
;   mov ecx, 0x40
;   mov rax, r11
;   sub rcx, rcx, rax
;   mov r9, rsi
;   shl r9, r9, cl
;   xor r11, r11, r11
;   test rax, $127
;   cmovz r9, r11, r9
;   or r8, r8, r9
;   mov rdx, rsi
;   sar rdx, rdx, 0x3f
;   test rax, $64
;   mov rax, r10
;   cmovz rax, r8, rax
;   cmovz rdx, r10, rdx
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rcx, rdx
;   mov r11, rdx
;   mov r8, rdi
;   shr r8, cl
;   mov r10, rsi
;   sar r10, cl
;   mov r11, rcx
;   mov ecx, 0x40
;   mov rax, r11
;   sub rcx, rax
;   mov r9, rsi
;   shl r9, cl
;   xor r11, r11
;   test rax, 0x7f
;   cmove r9, r11
;   or r8, r9
;   mov rdx, rsi
;   sar rdx, 0x3f
;   test rax, 0x40
;   mov rax, r10
;   cmove rax, r8
;   cmove rdx, r10
;   mov rsp, rbp
;   pop rbp
;   ret

function %f33(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = rotl v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rcx, rdx
;   mov r8, rdx
;   mov rdx, rdi
;   shl rdx, rdx, cl
;   mov r8, rcx
;   mov r11, rsi
;   shl r11, r11, cl
;   mov ecx, 0x40
;   mov rax, r8
;   sub rcx, rcx, rax
;   mov r10, rdi
;   shr r10, r10, cl
;   xor rax, rax, rax
;   mov rcx, r8
;   test rcx, $127
;   cmovz r10, rax, r10
;   or r10, r10, r11
;   test rcx, $64
;   cmovz rax, rdx, rax
;   cmovz rdx, r10, rdx
;   mov ecx, 0x80
;   mov r10, r8
;   sub rcx, rcx, r10
;   mov r8, rdi
;   shr r8, r8, cl
;   mov r9, rsi
;   shr r9, r9, cl
;   mov r10, rcx
;   mov ecx, 0x40
;   mov r11, r10
;   sub rcx, rcx, r11
;   mov r10, rsi
;   shl r10, r10, cl
;   xor rsi, rsi, rsi
;   test r11, $127
;   cmovz r10, rsi, r10
;   or r10, r10, r8
;   test r11, $64
;   mov r8, r9
;   cmovz r8, r10, r8
;   cmovz rsi, r9, rsi
;   or rax, rax, r8
;   or rdx, rdx, rsi
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rcx, rdx
;   mov r8, rdx
;   mov rdx, rdi
;   shl rdx, cl
;   mov r8, rcx
;   mov r11, rsi
;   shl r11, cl
;   mov ecx, 0x40
;   mov rax, r8
;   sub rcx, rax
;   mov r10, rdi
;   shr r10, cl
;   xor rax, rax
;   mov rcx, r8
;   test rcx, 0x7f
;   cmove r10, rax
;   or r10, r11
;   test rcx, 0x40
;   cmove rax, rdx
;   cmove rdx, r10
;   mov ecx, 0x80
;   mov r10, r8
;   sub rcx, r10
;   mov r8, rdi
;   shr r8, cl
;   mov r9, rsi
;   shr r9, cl
;   mov r10, rcx
;   mov ecx, 0x40
;   mov r11, r10
;   sub rcx, r11
;   mov r10, rsi
;   shl r10, cl
;   xor rsi, rsi
;   test r11, 0x7f
;   cmove r10, rsi
;   or r10, r8
;   test r11, 0x40
;   mov r8, r9
;   cmove r8, r10
;   cmove rsi, r9
;   or rax, r8
;   or rdx, rsi
;   mov rsp, rbp
;   pop rbp
;   ret

function %f34(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = rotr v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rcx, rdx
;   mov r9, rdx
;   mov r8, rdi
;   shr r8, r8, cl
;   mov r9, rcx
;   mov r10, rsi
;   shr r10, r10, cl
;   mov ecx, 0x40
;   mov rax, r9
;   sub rcx, rcx, rax
;   mov r11, rsi
;   shl r11, r11, cl
;   xor rdx, rdx, rdx
;   mov rcx, r9
;   test rcx, $127
;   cmovz r11, rdx, r11
;   or r11, r11, r8
;   test rcx, $64
;   mov rax, r10
;   cmovz rax, r11, rax
;   cmovz rdx, r10, rdx
;   mov ecx, 0x80
;   mov r10, r9
;   sub rcx, rcx, r10
;   mov r8, rdi
;   shl r8, r8, cl
;   mov r10, rsi
;   shl r10, r10, cl
;   mov r9, rcx
;   mov ecx, 0x40
;   mov rsi, r9
;   sub rcx, rcx, rsi
;   mov r9, rdi
;   shr r9, r9, cl
;   xor r11, r11, r11
;   test rsi, $127
;   cmovz r9, r11, r9
;   or r9, r9, r10
;   test rsi, $64
;   cmovz r11, r8, r11
;   cmovz r8, r9, r8
;   or rax, rax, r11
;   or rdx, rdx, r8
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rcx, rdx
;   mov r9, rdx
;   mov r8, rdi
;   shr r8, cl
;   mov r9, rcx
;   mov r10, rsi
;   shr r10, cl
;   mov ecx, 0x40
;   mov rax, r9
;   sub rcx, rax
;   mov r11, rsi
;   shl r11, cl
;   xor rdx, rdx
;   mov rcx, r9
;   test rcx, 0x7f
;   cmove r11, rdx
;   or r11, r8
;   test rcx, 0x40
;   mov rax, r10
;   cmove rax, r11
;   cmove rdx, r10
;   mov ecx, 0x80
;   mov r10, r9
;   sub rcx, r10
;   mov r8, rdi
;   shl r8, cl
;   mov r10, rsi
;   shl r10, cl
;   mov r9, rcx
;   mov ecx, 0x40
;   mov rsi, r9
;   sub rcx, rsi
;   mov r9, rdi
;   shr r9, cl
;   xor r11, r11
;   test rsi, 0x7f
;   cmove r9, r11
;   or r9, r10
;   test rsi, 0x40
;   cmove r11, r8
;   cmove r8, r9
;   or rax, r11
;   or rdx, r8
;   mov rsp, rbp
;   pop rbp
;   ret

