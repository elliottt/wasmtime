test compile precise-output
set enable_simd
target x86_64

function %punpcklbw(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, 0x17071606150514041303120211011000
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   punpcklbw xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   punpcklbw xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %punpckhbw(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, 0x1f0f1e0e1d0d1c0c1b0b1a0a19091808
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   punpckhbw xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   punpckhbw xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %punpcklwd(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [0 1 16 17 2 3 18 19 4 5 20 21 6 7 22 23]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   punpcklwd xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   punpcklwd xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %punpckhwd(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [8 9 24 25 10 11 26 27 12 13 28 29 14 15 30 31]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   punpckhwd xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   punpckhwd xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %pshufd_0022(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [0 1 2 3 0 1 2 3 8 9 10 11 8 9 10 11]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshufd xmm0, xmm0, 160
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshufd xmm0, xmm0, 0xa0
;   mov rsp, rbp
;   pop rbp
;   ret

function %pshufd_3120(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [12 13 14 15 4 5 6 7 8 9 10 11 0 1 2 3]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshufd xmm0, xmm0, 39
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshufd xmm0, xmm0, 0x27
;   mov rsp, rbp
;   pop rbp
;   ret

function %pshufd_7546(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [28 29 30 31 20 21 22 23 16 17 18 19 24 25 26 27]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshufd xmm0, xmm1, 135
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshufd xmm0, xmm1, 0x87
;   mov rsp, rbp
;   pop rbp
;   ret

function %not_single_pshufd(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [8 9 10 11 12 13 14 15 20 21 22 23 20 21 22 23]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   shufps xmm0, xmm0, xmm1, 0x5e
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   shufps xmm0, xmm1, 0x5e
;   mov rsp, rbp
;   pop rbp
;   ret

function %punpckldq(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [0 1 2 3 16 17 18 19 4 5 6 7 20 21 22 23]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   punpckldq xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   punpckldq xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %punpckhdq(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [8 9 10 11 24 25 26 27 12 13 14 15 28 29 30 31]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   punpckhdq xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   punpckhdq xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %punpcklqdq(i64x2, i64x2) -> i64x2 {
block0(v0: i64x2, v1: i64x2):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [0 1 2 3 4 5 6 7 16 17 18 19 20 21 22 23]
    v5 = bitcast.i64x2 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   punpcklqdq xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   punpcklqdq xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %punpckhqdq(i64x2, i64x2) -> i64x2 {
block0(v0: i64x2, v1: i64x2):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [8 9 10 11 12 13 14 15 24 25 26 27 28 29 30 31]
    v5 = bitcast.i64x2 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   punpckhqdq xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   punpckhqdq xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %shufps_3277(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [12 13 14 15 8 9 10 11 28 29 30 31 28 29 30 31]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   shufps xmm0, xmm0, xmm1, 0xfb
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   shufps xmm0, xmm1, 0xfb
;   mov rsp, rbp
;   pop rbp
;   ret

function %shufps_6500(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [24 25 26 27 20 21 22 23 0 1 2 3 0 1 2 3]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm4, xmm0
;   movdqa xmm0, xmm1
;   shufps xmm0, xmm0, xmm4, 0x6
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm4, xmm0
;   movdqa xmm0, xmm1
;   shufps xmm0, xmm4, 6
;   mov rsp, rbp
;   pop rbp
;   ret

function %pshuflw_3210(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [6 7 4 5 2 3 0 1 8 9 10 11 12 13 14 15]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshuflw xmm0, xmm0, 27
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshuflw xmm0, xmm0, 0x1b
;   mov rsp, rbp
;   pop rbp
;   ret

function %pshuflw_3131(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [6 7 4 5 6 7 4 5 8 9 10 11 12 13 14 15]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshuflw xmm0, xmm0, 187
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshuflw xmm0, xmm0, 0xbb
;   mov rsp, rbp
;   pop rbp
;   ret

function %pshuflw_rhs_3210(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [22 23 20 21 18 19 16 17 24 25 26 27 28 29 30 31]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshuflw xmm0, xmm1, 27
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshuflw xmm0, xmm1, 0x1b
;   mov rsp, rbp
;   pop rbp
;   ret

function %pshuflw_rhs_3131(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [22 23 18 19 22 23 18 19 24 25 26 27 28 29 30 31]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshuflw xmm0, xmm1, 119
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshuflw xmm0, xmm1, 0x77
;   mov rsp, rbp
;   pop rbp
;   ret

function %pshufhw_3210(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [0 1 2 3 4 5 6 7 14 15 12 13 10 11 8 9]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshufhw xmm0, xmm0, 27
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshufhw xmm0, xmm0, 0x1b
;   mov rsp, rbp
;   pop rbp
;   ret

function %pshufhw_3131(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [0 1 2 3 4 5 6 7 14 15 10 11 14 15 10 11]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshufhw xmm0, xmm0, 119
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshufhw xmm0, xmm0, 0x77
;   mov rsp, rbp
;   pop rbp
;   ret

function %pshufhw_rhs_3210(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [16 17 18 19 20 21 22 23 30 31 28 29 26 27 24 25]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshufhw xmm0, xmm1, 27
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshufhw xmm0, xmm1, 0x1b
;   mov rsp, rbp
;   pop rbp
;   ret

function %pshufhw_rhs_3131(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [16 17 18 19 20 21 22 23 30 31 26 27 30 31 26 27]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshufhw xmm0, xmm1, 119
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshufhw xmm0, xmm1, 0x77
;   mov rsp, rbp
;   pop rbp
;   ret

function %shuffle_all_zeros(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   uninit xmm4
;   pxor xmm4, xmm4, xmm4
;   pshufb xmm0, xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pxor xmm4, xmm4
;   pshufb xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret

function %palignr_0(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pblendw xmm0, xmm0, xmm1, 0x0
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pblendw xmm0, xmm1, 0
;   mov rsp, rbp
;   pop rbp
;   ret

function %palignr_1(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, [1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16]
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm4, xmm0
;   movdqa xmm0, xmm1
;   palignr xmm0, xmm0, xmm4, 0x1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm4, xmm0
;   movdqa xmm0, xmm1
;   palignr xmm0, xmm4, 1
;   mov rsp, rbp
;   pop rbp
;   ret

function %palignr_5(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, [5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20]
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm4, xmm0
;   movdqa xmm0, xmm1
;   palignr xmm0, xmm0, xmm4, 0x5
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm4, xmm0
;   movdqa xmm0, xmm1
;   palignr xmm0, xmm4, 5
;   mov rsp, rbp
;   pop rbp
;   ret

function %palignr_11(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, [11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26]
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm4, xmm0
;   movdqa xmm0, xmm1
;   palignr xmm0, xmm0, xmm4, 0xb
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm4, xmm0
;   movdqa xmm0, xmm1
;   palignr xmm0, xmm4, 0xb
;   mov rsp, rbp
;   pop rbp
;   ret

function %palignr_16(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pblendw xmm0, xmm0, xmm1, 0xff
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pblendw xmm0, xmm1, 0xff
;   mov rsp, rbp
;   pop rbp
;   ret

function %pblendw_0b10011001(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [16 17 2 3 4 5 22 23 24 25 10 11 12 13 30 31]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pblendw xmm0, xmm0, xmm1, 0x99
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pblendw xmm0, xmm1, 0x99
;   mov rsp, rbp
;   pop rbp
;   ret

