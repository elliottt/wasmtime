test compile precise-output
set enable_simd
target x86_64 has_sse3 has_ssse3 has_sse41

;; shuffle

function %shuffle_different_ssa_values() -> i8x16 {
block0:
    v0 = vconst.i8x16 0x00
    v1 = vconst.i8x16 0x01
    v2 = shuffle v0, v1, 0x11000000000000000000000000000000     ;; pick the second lane of v1, the rest use the first lane of v0
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqu xmm0, const(3)
;   movdqu xmm2, const(2)
;   pshufb xmm0, xmm0, const(0)
;   pshufb xmm2, xmm2, const(1)
;   por xmm0, xmm0, xmm2
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqu xmm0, xmmword ptr [rip + 0x24]
;   movdqu xmm2, xmmword ptr [rip + 0x2c]
;   pshufb xmm0, xmmword ptr [rip + 0x33]
;   pshufb xmm2, xmmword ptr [rip + 0x3a]
;   por xmm0, xmm2
;   mov rsp, rbp
;   pop rbp
;   ret
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rcx], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax - 0x7f7f7f80], 0x80
;   add byte ptr [rax - 0x7f7f7f80], 0x80

function %shuffle_same_ssa_value() -> i8x16 {
block0:
    v1 = vconst.i8x16 0x01
    v2 = shuffle v1, v1, 0x13000000000000000000000000000000     ;; pick the fourth lane of v1 and the rest from the first lane of v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqu xmm0, const(1)
;   pshufb xmm0, xmm0, const(0)
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqu xmm0, xmmword ptr [rip + 0x14]
;   pshufb xmm0, xmmword ptr [rip + 0x1b]
;   mov rsp, rbp
;   pop rbp
;   ret
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add dword ptr [rax], eax
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rbx], al

function %swizzle() -> i8x16 {
block0:
    v0 = vconst.i8x16 [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]
    v1 = vconst.i8x16 [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]
    v2 = swizzle v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqu xmm0, const(1)
;   movdqu xmm1, const(1)
;   paddusb xmm1, xmm1, const(0)
;   pshufb xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqu xmm0, xmmword ptr [rip + 0x24]
;   movdqu xmm1, xmmword ptr [rip + 0x1c]
;   paddusb xmm1, xmmword ptr [rip + 0x24]
;   pshufb xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rcx], al
;   add al, byte ptr [rbx]
;   add al, 5

function %splat_i8(i8) -> i8x16 {
block0(v0: i8):
    v1 = splat.i8x16 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movd xmm0, edi
;   uninit xmm5
;   pxor xmm5, xmm5, xmm5
;   pshufb xmm0, xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movd xmm0, edi
;   pxor xmm5, xmm5
;   pshufb xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret

function %splat_i16() -> i16x8 {
block0:
    v0 = iconst.i16 -1
    v1 = splat.i16x8 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov ecx, 0xffffffff
;   movd xmm1, ecx
;   pshuflw xmm3, xmm1, 0
;   pshufd xmm0, xmm3, 0
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov ecx, 0xffffffff
;   movd xmm1, ecx
;   pshuflw xmm3, xmm1, 0
;   pshufd xmm0, xmm3, 0
;   mov rsp, rbp
;   pop rbp
;   ret

function %splat_i32(i32) -> i32x4 {
block0(v0: i32):
    v1 = splat.i32x4 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movd xmm2, edi
;   pshufd xmm0, xmm2, 0
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movd xmm2, edi
;   pshufd xmm0, xmm2, 0
;   mov rsp, rbp
;   pop rbp
;   ret

function %splat_f64(f64) -> f64x2 {
block0(v0: f64):
    v1 = splat.f64x2 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movddup xmm0, xmm0
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movddup xmm0, xmm0
;   mov rsp, rbp
;   pop rbp
;   ret

function %load32_zero_coalesced(i64) -> i32x4 {
block0(v0: i64):
    v1 = load.i32 v0
    v2 = scalar_to_vector.i32x4 v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movss xmm0, qword ptr [rdi + 0x0]
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movss xmm0, dword ptr [rdi] ; trap: heap_oob
;   mov rsp, rbp
;   pop rbp
;   ret

function %load32_zero_int(i32) -> i32x4 {
block0(v0: i32):
    v1 = scalar_to_vector.i32x4 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movd xmm0, edi
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movd xmm0, edi
;   mov rsp, rbp
;   pop rbp
;   ret

function %load32_zero_float(f32) -> f32x4 {
block0(v0: f32):
    v1 = scalar_to_vector.f32x4 v0
    return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rsp, rbp
;   pop rbp
;   ret

