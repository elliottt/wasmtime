test compile precise-output
set enable_simd
target x86_64

function %band_f32x4(f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4):
    v2 = band v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   andps xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   andps xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %band_f64x2(f64x2, f64x2) -> f64x2 {
block0(v0: f64x2, v1: f64x2):
    v2 = band v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   andpd xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   andpd xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %band_i32x4(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = band v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pand xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pand xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %bor_f32x4(f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4):
    v2 = bor v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   orps xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   orps xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %bor_f64x2(f64x2, f64x2) -> f64x2 {
block0(v0: f64x2, v1: f64x2):
    v2 = bor v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   orpd xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   orpd xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %bor_i32x4(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bor v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   por xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   por xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %bxor_f32x4(f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4):
    v2 = bxor v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   xorps xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   xorps xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %bxor_f64x2(f64x2, f64x2) -> f64x2 {
block0(v0: f64x2, v1: f64x2):
    v2 = bxor v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   xorpd xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   xorpd xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %bxor_i32x4(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bxor v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pxor xmm0, xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pxor xmm0, xmm1
;   mov rsp, rbp
;   pop rbp
;   ret

function %vselect_i16x8(i16x8, i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8, v2: i16x8):
    v3 = bitselect v0, v1, v2
    return v3
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm4, xmm1
;   pand xmm4, xmm4, xmm0
;   pandn xmm0, xmm0, xmm2
;   por xmm0, xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm4, xmm1
;   pand xmm4, xmm0
;   pandn xmm0, xmm2
;   por xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret

function %vselect_f32x4(f32x4, f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4, v2: f32x4):
    v3 = bitselect v0, v1, v2
    return v3
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm4, xmm1
;   andps xmm4, xmm4, xmm0
;   andnps xmm0, xmm0, xmm2
;   orps xmm0, xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm4, xmm1
;   andps xmm4, xmm0
;   andnps xmm0, xmm2
;   orps xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret

function %vselect_f64x2(f64x2, f64x2, f64x2) -> f64x2 {
block0(v0: f64x2, v1: f64x2, v2: f64x2):
    v3 = bitselect v0, v1, v2
    return v3
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm4, xmm1
;   andpd xmm4, xmm4, xmm0
;   andnpd xmm0, xmm0, xmm2
;   orpd xmm0, xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm4, xmm1
;   andpd xmm4, xmm0
;   andnpd xmm0, xmm2
;   orpd xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret

function %ishl_i8x16(i32) -> i8x16 {
block0(v0: i32):
    v1 = vconst.i8x16 [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]
    v2 = ishl v1, v0
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqu xmm0, const(1)
;   mov r10, rdi
;   and r10, r10, $7
;   movd xmm5, r10d
;   psllw xmm0, xmm0, xmm5
;   lea rsi, const(0)
;   shl r10, r10, 0x4
;   movdqu xmm13, xmmword ptr [rsi + r10]
;   pand xmm0, xmm0, xmm13
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqu xmm0, xmmword ptr [rip + 0x34]
;   mov r10, rdi
;   and r10, 7
;   movd xmm5, r10d
;   psllw xmm0, xmm5
;   lea rsi, [rip + 0x2d]
;   shl r10, 4
;   movdqu xmm13, xmmword ptr [rsi + r10]
;   pand xmm0, xmm13
;   mov rsp, rbp
;   pop rbp
;   ret
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add dword ptr [rdx], eax
;   add eax, dword ptr [rax + 0x9080706]
;   or cl, byte ptr [rbx]
;   or al, 0xd

function %ishl_i8x16_imm(i8x16) -> i8x16 {
block0(v0: i8x16):
    v1 = iconst.i32 124
    v2 = ishl v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   psllw xmm0, xmm0, $4
;   movdqu xmm4, const(0)
;   pand xmm0, xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   psllw xmm0, 4
;   movdqu xmm4, xmmword ptr [rip + 0xf]
;   pand xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al

function %ishl_i16x8_imm(i16x8) -> i16x8 {
block0(v0: i16x8):
    v1 = iconst.i32 1
    v2 = ishl v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   psllw xmm0, xmm0, $1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   psllw xmm0, 1
;   mov rsp, rbp
;   pop rbp
;   ret

function %ishl_i32x4_imm(i32x4) -> i32x4 {
block0(v0: i32x4):
    v1 = iconst.i32 100
    v2 = ishl v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pslld xmm0, xmm0, $4
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pslld xmm0, 4
;   mov rsp, rbp
;   pop rbp
;   ret

function %ishl_i64x2_imm(i64x2) -> i64x2 {
block0(v0: i64x2):
    v1 = iconst.i32 100
    v2 = ishl v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   psllq xmm0, xmm0, $36
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   psllq xmm0, 0x24
;   mov rsp, rbp
;   pop rbp
;   ret

function %ushr_i8x16_imm() -> i8x16 {
block0:
    v0 = iconst.i32 1
    v1 = vconst.i8x16 [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]
    v2 = ushr v1, v0
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqu xmm0, const(1)
;   psrlw xmm0, xmm0, $1
;   pand xmm0, xmm0, const(0)
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqu xmm0, xmmword ptr [rip + 0x14]
;   psrlw xmm0, 1
;   pand xmm0, xmmword ptr [rip + 0x17]
;   mov rsp, rbp
;   pop rbp
;   ret
;   add byte ptr [rax], al
;   add byte ptr [rcx], al
;   add al, byte ptr [rbx]
;   add al, 5

function %ushr_i16x8_imm(i16x8) -> i16x8 {
block0(v0: i16x8):
    v1 = iconst.i32 1
    v2 = ushr v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   psrlw xmm0, xmm0, $1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   psrlw xmm0, 1
;   mov rsp, rbp
;   pop rbp
;   ret

function %ushr_i32x4_imm(i32x4) -> i32x4 {
block0(v0: i32x4):
    v1 = iconst.i32 100
    v2 = ushr v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   psrld xmm0, xmm0, $4
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   psrld xmm0, 4
;   mov rsp, rbp
;   pop rbp
;   ret

function %ushr_i64x2_imm(i64x2) -> i64x2 {
block0(v0: i64x2):
    v1 = iconst.i32 100
    v2 = ushr v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   psrlq xmm0, xmm0, $36
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   psrlq xmm0, 0x24
;   mov rsp, rbp
;   pop rbp
;   ret

function %sshr_i8x16(i32) -> i8x16 {
block0(v0: i32):
    v1 = vconst.i8x16 [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]
    v2 = sshr v1, v0
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqu xmm8, const(0)
;   mov r9, rdi
;   and r9, r9, $7
;   movdqa xmm0, xmm8
;   punpcklbw xmm0, xmm0, xmm8
;   punpckhbw xmm8, xmm8, xmm8
;   add r9d, r9d, $8
;   movd xmm11, r9d
;   psraw xmm0, xmm0, xmm11
;   psraw xmm8, xmm8, xmm11
;   packsswb xmm0, xmm0, xmm8
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqu xmm8, xmmword ptr [rip + 0x33]
;   mov r9, rdi
;   and r9, 7
;   movdqa xmm0, xmm8
;   punpcklbw xmm0, xmm8
;   punpckhbw xmm8, xmm8
;   add r9d, 8
;   movd xmm11, r9d
;   psraw xmm0, xmm11
;   psraw xmm8, xmm11
;   packsswb xmm0, xmm8
;   mov rsp, rbp
;   pop rbp
;   ret
;   add byte ptr [rcx], al
;   add al, byte ptr [rbx]
;   add al, 5

function %sshr_i8x16_imm(i8x16, i32) -> i8x16 {
block0(v0: i8x16, v1: i32):
    v2 = sshr_imm v0, 3
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm7, xmm0
;   punpcklbw xmm7, xmm7, xmm0
;   movdqa xmm8, xmm7
;   movdqa xmm7, xmm0
;   punpckhbw xmm7, xmm7, xmm0
;   movdqa xmm0, xmm8
;   psraw xmm0, xmm0, $11
;   psraw xmm7, xmm7, $11
;   packsswb xmm0, xmm0, xmm7
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm7, xmm0
;   punpcklbw xmm7, xmm0
;   movdqa xmm8, xmm7
;   movdqa xmm7, xmm0
;   punpckhbw xmm7, xmm0
;   movdqa xmm0, xmm8
;   psraw xmm0, 0xb
;   psraw xmm7, 0xb
;   packsswb xmm0, xmm7
;   mov rsp, rbp
;   pop rbp
;   ret

function %sshr_i16x8_imm(i16x8) -> i16x8 {
block0(v0: i16x8):
    v1 = iconst.i32 1
    v2 = sshr v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   psraw xmm0, xmm0, $1
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   psraw xmm0, 1
;   mov rsp, rbp
;   pop rbp
;   ret

function %sshr_i32x4_imm(i32x4) -> i32x4 {
block0(v0: i32x4):
    v1 = iconst.i32 100
    v2 = sshr v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   psrad xmm0, xmm0, $4
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   psrad xmm0, 4
;   mov rsp, rbp
;   pop rbp
;   ret

function %sshr_i64x2_imm1(i64x2) -> i64x2 {
block0(v0: i64x2):
    v1 = iconst.i32 1
    v2 = sshr v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm2, xmm0
;   psrad xmm2, xmm2, $1
;   pshufd xmm4, xmm2, 237
;   movdqa xmm6, xmm0
;   psrlq xmm6, xmm6, $1
;   pshufd xmm0, xmm6, 232
;   punpckldq xmm0, xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm2, xmm0
;   psrad xmm2, 1
;   pshufd xmm4, xmm2, 0xed
;   movdqa xmm6, xmm0
;   psrlq xmm6, 1
;   pshufd xmm0, xmm6, 0xe8
;   punpckldq xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret

function %sshr_i64x2_imm32(i64x2) -> i64x2 {
block0(v0: i64x2):
    v1 = iconst.i32 32
    v2 = sshr v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshufd xmm5, xmm0, 237
;   movdqa xmm4, xmm0
;   psrad xmm4, xmm4, $31
;   pshufd xmm6, xmm4, 237
;   movdqa xmm0, xmm5
;   punpckldq xmm0, xmm0, xmm6
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshufd xmm5, xmm0, 0xed
;   movdqa xmm4, xmm0
;   psrad xmm4, 0x1f
;   pshufd xmm6, xmm4, 0xed
;   movdqa xmm0, xmm5
;   punpckldq xmm0, xmm6
;   mov rsp, rbp
;   pop rbp
;   ret

function %sshr_i64x2_imm54(i64x2) -> i64x2 {
block0(v0: i64x2):
    v1 = iconst.i32 54
    v2 = sshr v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm2, xmm0
;   psrad xmm2, xmm2, $31
;   pshufd xmm4, xmm2, 237
;   movdqa xmm6, xmm0
;   psrad xmm6, xmm6, $22
;   pshufd xmm0, xmm6, 233
;   punpckldq xmm0, xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm2, xmm0
;   psrad xmm2, 0x1f
;   pshufd xmm4, xmm2, 0xed
;   movdqa xmm6, xmm0
;   psrad xmm6, 0x16
;   pshufd xmm0, xmm6, 0xe9
;   punpckldq xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret

function %sshr_i64x2_imm(i64x2) -> i64x2 {
block0(v0: i64x2):
    v1 = iconst.i32 100
    v2 = sshr v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm2, xmm0
;   psrad xmm2, xmm2, $31
;   pshufd xmm4, xmm2, 237
;   movdqa xmm6, xmm0
;   psrad xmm6, xmm6, $4
;   pshufd xmm0, xmm6, 233
;   punpckldq xmm0, xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm2, xmm0
;   psrad xmm2, 0x1f
;   pshufd xmm4, xmm2, 0xed
;   movdqa xmm6, xmm0
;   psrad xmm6, 4
;   pshufd xmm0, xmm6, 0xe9
;   punpckldq xmm0, xmm4
;   mov rsp, rbp
;   pop rbp
;   ret

function %sshr_i64x2(i64x2, i32) -> i64x2 {
block0(v0: i64x2, v1: i32):
    v2 = sshr v0, v1
    return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   mov rcx, rdi
;   and rcx, rcx, $63
;   movq xmm5, rcx
;   movdqu xmm8, const(0)
;   psrlq xmm8, xmm8, xmm5
;   movdqa xmm11, xmm0
;   psrlq xmm11, xmm11, xmm5
;   movdqa xmm0, xmm8
;   pxor xmm0, xmm0, xmm11
;   psubq xmm0, xmm0, xmm8
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   mov rcx, rdi
;   and rcx, 0x3f
;   movq xmm5, rcx
;   movdqu xmm8, xmmword ptr [rip + 0x27]
;   psrlq xmm8, xmm5
;   movdqa xmm11, xmm0
;   psrlq xmm11, xmm5
;   movdqa xmm0, xmm8
;   pxor xmm0, xmm11
;   psubq xmm0, xmm8
;   mov rsp, rbp
;   pop rbp
;   ret
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al
;   add byte ptr [rax], al

