

test compile precise-output
set enable_simd
target x86_64

function %imul_swiden_hi_i8x16(i8x16, i8x16) -> i16x8 {
block0(v0: i8x16, v1: i8x16):
    v2 = swiden_high v0
    v3 = swiden_high v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm6, xmm0
;   palignr xmm6, xmm6, xmm0, 0x8
;   pmovsxbw xmm0, xmm6
;   movdqa xmm6, xmm1
;   palignr xmm6, xmm6, xmm1, 0x8
;   pmovsxbw xmm8, xmm6
;   pmullw xmm0, xmm0, xmm8
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm6, xmm0
;   palignr xmm6, xmm0, 8
;   pmovsxbw xmm0, xmm6
;   movdqa xmm6, xmm1
;   palignr xmm6, xmm1, 8
;   pmovsxbw xmm8, xmm6
;   pmullw xmm0, xmm8
;   mov rsp, rbp
;   pop rbp
;   ret

function %imul_swiden_hi_i16x8(i16x8, i16x8) -> i32x4 {
block0(v0: i16x8, v1: i16x8):
    v2 = swiden_high v0
    v3 = swiden_high v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm5, xmm0
;   pmullw xmm5, xmm5, xmm1
;   movdqa xmm6, xmm5
;   movdqa xmm5, xmm0
;   pmulhw xmm5, xmm5, xmm1
;   movdqa xmm0, xmm6
;   punpckhwd xmm0, xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm5, xmm0
;   pmullw xmm5, xmm1
;   movdqa xmm6, xmm5
;   movdqa xmm5, xmm0
;   pmulhw xmm5, xmm1
;   movdqa xmm0, xmm6
;   punpckhwd xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret

function %imul_swiden_hi_i32x4(i32x4, i32x4) -> i64x2 {
block0(v0: i32x4, v1: i32x4):
    v2 = swiden_high v0
    v3 = swiden_high v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshufd xmm0, xmm0, 250
;   pshufd xmm5, xmm1, 250
;   pmuldq xmm0, xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshufd xmm0, xmm0, 0xfa
;   pshufd xmm5, xmm1, 0xfa
;   pmuldq xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret

function %imul_swiden_low_i8x16(i8x16, i8x16) -> i16x8 {
block0(v0: i8x16, v1: i8x16):
    v2 = swiden_low v0
    v3 = swiden_low v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pmovsxbw xmm0, xmm0
;   pmovsxbw xmm5, xmm1
;   pmullw xmm0, xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pmovsxbw xmm0, xmm0
;   pmovsxbw xmm5, xmm1
;   pmullw xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret

function %imul_swiden_low_i16x8(i16x8, i16x8) -> i32x4 {
block0(v0: i16x8, v1: i16x8):
    v2 = swiden_low v0
    v3 = swiden_low v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm5, xmm0
;   pmullw xmm5, xmm5, xmm1
;   movdqa xmm6, xmm5
;   movdqa xmm5, xmm0
;   pmulhw xmm5, xmm5, xmm1
;   movdqa xmm0, xmm6
;   punpcklwd xmm0, xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm5, xmm0
;   pmullw xmm5, xmm1
;   movdqa xmm6, xmm5
;   movdqa xmm5, xmm0
;   pmulhw xmm5, xmm1
;   movdqa xmm0, xmm6
;   punpcklwd xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret

function %imul_swiden_low_i32x4(i32x4, i32x4) -> i64x2 {
block0(v0: i32x4, v1: i32x4):
    v2 = swiden_low v0
    v3 = swiden_low v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshufd xmm0, xmm0, 80
;   pshufd xmm5, xmm1, 80
;   pmuldq xmm0, xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshufd xmm0, xmm0, 0x50
;   pshufd xmm5, xmm1, 0x50
;   pmuldq xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret

function %imul_uwiden_hi_i8x16(i8x16, i8x16) -> i16x8 {
block0(v0: i8x16, v1: i8x16):
    v2 = uwiden_high v0
    v3 = uwiden_high v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   uninit xmm8
;   pxor xmm8, xmm8, xmm8
;   punpckhbw xmm0, xmm0, xmm8
;   uninit xmm8
;   pxor xmm8, xmm8, xmm8
;   movdqa xmm11, xmm1
;   punpckhbw xmm11, xmm11, xmm8
;   pmullw xmm0, xmm0, xmm11
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pxor xmm8, xmm8
;   punpckhbw xmm0, xmm8
;   pxor xmm8, xmm8
;   movdqa xmm11, xmm1
;   punpckhbw xmm11, xmm8
;   pmullw xmm0, xmm11
;   mov rsp, rbp
;   pop rbp
;   ret

function %imul_uwiden_hi_i16x8(i16x8, i16x8) -> i32x4 {
block0(v0: i16x8, v1: i16x8):
    v2 = uwiden_high v0
    v3 = uwiden_high v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm5, xmm0
;   pmullw xmm5, xmm5, xmm1
;   movdqa xmm6, xmm5
;   movdqa xmm5, xmm0
;   pmulhuw xmm5, xmm5, xmm1
;   movdqa xmm0, xmm6
;   punpckhwd xmm0, xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm5, xmm0
;   pmullw xmm5, xmm1
;   movdqa xmm6, xmm5
;   movdqa xmm5, xmm0
;   pmulhuw xmm5, xmm1
;   movdqa xmm0, xmm6
;   punpckhwd xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret

function %imul_uwiden_hi_i32x4(i32x4, i32x4) -> i64x2 {
block0(v0: i32x4, v1: i32x4):
    v2 = uwiden_high v0
    v3 = uwiden_high v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshufd xmm0, xmm0, 250
;   pshufd xmm5, xmm1, 250
;   pmuludq xmm0, xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshufd xmm0, xmm0, 0xfa
;   pshufd xmm5, xmm1, 0xfa
;   pmuludq xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret

function %imul_uwiden_low_i8x16(i8x16, i8x16) -> i16x8 {
block0(v0: i8x16, v1: i8x16):
    v2 = uwiden_low v0
    v3 = uwiden_low v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pmovzxbw xmm0, xmm0
;   pmovzxbw xmm5, xmm1
;   pmullw xmm0, xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pmovzxbw xmm0, xmm0
;   pmovzxbw xmm5, xmm1
;   pmullw xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret

function %imul_uwiden_low_i16x8(i16x8, i16x8) -> i32x4 {
block0(v0: i16x8, v1: i16x8):
    v2 = uwiden_low v0
    v3 = uwiden_low v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   movdqa xmm5, xmm0
;   pmullw xmm5, xmm5, xmm1
;   movdqa xmm6, xmm5
;   movdqa xmm5, xmm0
;   pmulhuw xmm5, xmm5, xmm1
;   movdqa xmm0, xmm6
;   punpcklwd xmm0, xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   movdqa xmm5, xmm0
;   pmullw xmm5, xmm1
;   movdqa xmm6, xmm5
;   movdqa xmm5, xmm0
;   pmulhuw xmm5, xmm1
;   movdqa xmm0, xmm6
;   punpcklwd xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret

function %imul_uwiden_low_i32x4(i32x4, i32x4) -> i64x2 {
block0(v0: i32x4, v1: i32x4):
    v2 = uwiden_low v0
    v3 = uwiden_low v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   pshufd xmm0, xmm0, 80
;   pshufd xmm5, xmm1, 80
;   pmuludq xmm0, xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   pshufd xmm0, xmm0, 0x50
;   pshufd xmm5, xmm1, 0x50
;   pmuludq xmm0, xmm5
;   mov rsp, rbp
;   pop rbp
;   ret

