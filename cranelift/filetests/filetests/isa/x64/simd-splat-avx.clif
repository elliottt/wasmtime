test compile precise-output
set enable_simd
target x86_64 has_avx

function %splat_i8(i8) -> i8x16 {
block0(v0: i8):
  v1 = splat.i8x16 v0
  return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   vmovd xmm2, edi
;   uninit xmm4
;   vpxor xmm6, xmm4, xmm4
;   vpshufb xmm0, xmm2, xmm6
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   vmovd xmm2, edi
;   vpxor xmm6, xmm4, xmm4
;   vpshufb xmm0, xmm2, xmm6
;   mov rsp, rbp
;   pop rbp
;   ret

function %splat_i16(i16) -> i16x8 {
block0(v0: i16):
  v1 = splat.i16x8 v0
  return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   vmovd xmm2, edi
;   vpshuflw xmm4, xmm2, 0
;   vpshufd xmm0, xmm4, 0
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   vmovd xmm2, edi
;   vpshuflw xmm4, xmm2, 0
;   vpshufd xmm0, xmm4, 0
;   mov rsp, rbp
;   pop rbp
;   ret

function %splat_i32(i32) -> i32x4 {
block0(v0: i32):
  v1 = splat.i32x4 v0
  return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   vmovd xmm2, edi
;   vpshufd xmm0, xmm2, 0
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   vmovd xmm2, edi
;   vpshufd xmm0, xmm2, 0
;   mov rsp, rbp
;   pop rbp
;   ret

function %splat_i64(i64) -> i64x2 {
block0(v0: i64):
  v1 = splat.i64x2 v0
  return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   vmovq xmm2, rdi
;   vmovddup xmm0, xmm2
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   vmovq xmm2, rdi
;   vmovddup xmm0, xmm2
;   mov rsp, rbp
;   pop rbp
;   ret

function %splat_f32(f32) -> f32x4 {
block0(v0: f32):
  v1 = splat.f32x4 v0
  return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   vshufps xmm0, xmm0, xmm0, 0x0
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   vshufps xmm0, xmm0, xmm0, 0
;   mov rsp, rbp
;   pop rbp
;   ret

function %splat_f64(f64) -> f64x2 {
block0(v0: f64):
  v1 = splat.f64x2 v0
  return v1
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   vmovddup xmm0, xmm0
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   vmovddup xmm0, xmm0
;   mov rsp, rbp
;   pop rbp
;   ret

function %load_splat_i8(i64) -> i8x16 {
block0(v0: i64):
  v1 = load.i8 v0
  v2 = splat.i8x16 v1
  return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   uninit xmm2
;   vpinsrb xmm4, xmm2, qword ptr [rdi + 0x0], 0x0
;   uninit xmm6
;   vpxor xmm8, xmm6, xmm6
;   vpshufb xmm0, xmm4, xmm8
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   vpinsrb xmm4, xmm2, byte ptr [rdi], 0 ; trap: heap_oob
;   vpxor xmm8, xmm6, xmm6
;   vpshufb xmm0, xmm4, xmm8
;   mov rsp, rbp
;   pop rbp
;   ret

function %load_splat_i16(i64) -> i16x8 {
block0(v0: i64):
  v1 = load.i16 v0
  v2 = splat.i16x8 v1
  return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   uninit xmm2
;   vpinsrw xmm4, xmm2, qword ptr [rdi + 0x0], 0x0
;   vpshuflw xmm6, xmm4, 0
;   vpshufd xmm0, xmm6, 0
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   vpinsrw xmm4, xmm2, word ptr [rdi], 0 ; trap: heap_oob
;   vpshuflw xmm6, xmm4, 0
;   vpshufd xmm0, xmm6, 0
;   mov rsp, rbp
;   pop rbp
;   ret

function %load_splat_i32(i64) -> i32x4 {
block0(v0: i64):
  v1 = load.i32 v0
  v2 = splat.i32x4 v1
  return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   vbroadcastss xmm0, xmmword ptr [rdi + 0x0]
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   vbroadcastss xmm0, dword ptr [rdi] ; trap: heap_oob
;   mov rsp, rbp
;   pop rbp
;   ret

function %load_splat_i64(i64) -> i64x2 {
block0(v0: i64):
  v1 = load.i64 v0
  v2 = splat.i64x2 v1
  return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   vmovddup xmm0, xmmword ptr [rdi + 0x0]
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   vmovddup xmm0, qword ptr [rdi] ; trap: heap_oob
;   mov rsp, rbp
;   pop rbp
;   ret

function %load_splat_f32(i64) -> f32x4 {
block0(v0: i64):
  v1 = load.f32 v0
  v2 = splat.f32x4 v1
  return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   vbroadcastss xmm0, xmmword ptr [rdi + 0x0]
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   vbroadcastss xmm0, dword ptr [rdi] ; trap: heap_oob
;   mov rsp, rbp
;   pop rbp
;   ret

function %load_splat_f64(i64) -> f64x2 {
block0(v0: i64):
  v1 = load.f64 v0
  v2 = splat.f64x2 v1
  return v2
}

; VCode:
;   push rbp
;   mov rbp, rsp
; block0:
;   vmovddup xmm0, xmmword ptr [rdi + 0x0]
;   mov rsp, rbp
;   pop rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   push rbp
;   mov rbp, rsp
; block1: ; offset 0x4
;   vmovddup xmm0, qword ptr [rdi] ; trap: heap_oob
;   mov rsp, rbp
;   pop rbp
;   ret

